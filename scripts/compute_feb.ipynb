{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mplots\u001b[0m/              REF_L_RUN1_lam.npy   REF_RL_RUN1_feb.npy\r\n",
      "qsub.sh             REF_L_RUN2_feb.npy   REF_RL_RUN1_inc.npy\r\n",
      "\u001b[34;42mREF_L\u001b[0m/              REF_L_RUN2_inc.npy   REF_RL_RUN1_lam.npy\r\n",
      "REF_L_RUN0_feb.npy  REF_L_RUN2_lam.npy   REF_RL_RUN2_feb.npy\r\n",
      "REF_L_RUN0_inc.npy  \u001b[34;42mREF_RL\u001b[0m/              REF_RL_RUN2_inc.npy\r\n",
      "REF_L_RUN0_lam.npy  REF_RL_RUN0_feb.npy  REF_RL_RUN2_lam.npy\r\n",
      "REF_L_RUN1_feb.npy  REF_RL_RUN0_inc.npy  scrape.ipynb\r\n",
      "REF_L_RUN1_inc.npy  REF_RL_RUN0_lam.npy\r\n"
     ]
    }
   ],
   "source": [
    "%ls\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mdtraj as md\n",
    "import subprocess, collections\n",
    "import glob, tqdm, os\n",
    "import xvg_tools\n",
    "rc('font', weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace structure in dG1 with first frame of centered trajectory file\n",
    "# Replace distances in dG4 AND change MBAR function to compute potential for THREE restraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2655,) 398 155.30147557820118 148.90857\n",
      "(13909,) 6864 168.41655517104329 168.45462\n",
      "[6, 35, 23]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xvg_tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-55852efb16b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Compute dG4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtime_in_ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxvg_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dhdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{prefix}/{dataset}_RL/RUN{run}/dhdl.xvg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;31m#get just last few nanoseconds for estimating free energy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtime_in_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_in_ps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# stride to match xtc save frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xvg_tools' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = 'REF'\n",
    "prefix = '.'\n",
    "\n",
    "\n",
    "for run in range(len(glob.glob(f'{prefix}/{dataset}_RL/RUN*'))):\n",
    "    if not os.path.exists(f'results/scraped_data/{dataset}_RL_RUN{run}_feb.npy') or not os.path.exists(\n",
    "      f'scraped_data/{dataset}_L_RUN{run}_feb.npy'):\n",
    "        continue # skip if we don't have scraped free energies for dG2 and dG3\n",
    "    \n",
    "# Compute dG2 and dG3 \n",
    "    RL_increments = np.load(f'scraped_data/{dataset}_RL_RUN{run}_inc.npy')\n",
    "    RL_fe = np.load(f'scraped_data/{dataset}_RL_RUN{run}_feb.npy')[:,-1]\n",
    "    L_increments = np.load(f'scraped_data/{dataset}_L_RUN{run}_inc.npy')\n",
    "    L_fe = np.load(f'scraped_data/{dataset}_L_RUN{run}_feb.npy')[:,-1]\n",
    "    \n",
    "    for x,i in enumerate(L_increments):\n",
    "        if i < increment_threshold:\n",
    "            break\n",
    "    #print(np.shape(L_fe), x, np.average(L_fe[x:]), L_fe[-1]) # < --- decide which to use\n",
    "    dG2 = np.average(L_fe[x:]\n",
    "    \n",
    "    for x,i in enumerate(RL_increments):\n",
    "        if i < increment_threshold:\n",
    "            last_frames = x*10 # un-stride for later\n",
    "            break\n",
    "    #print(np.shape(RL_fe), x, np.average(RL_fe[x:]), RL_fe[-1])\n",
    "    dG3 = -np.average(RL_fe[x:])\n",
    "    \n",
    "# Compute dG1\n",
    "    itpfile = f'{prefix}/{dataset}_RL/RUN{run}/LIG_res.itp'\n",
    "    fin = open(itpfile, 'r')\n",
    "    lines = fin.readlines()\n",
    "    fin.close()\n",
    "\n",
    "    rest_lines = [line for line in lines if (line[0] != ';' and line[0] != '[')]\n",
    "    rest_indices = []\n",
    "    for line in rest_lines:\n",
    "        fields = line.strip().split()\n",
    "        rest_indices.append( int(fields[0]) )\n",
    "\n",
    "    structure = md.load(f'{prefix}/{dataset}_RL/RUN{run}/npt.gro') # <-- replace with traj\n",
    "    x1 = structure.xyz[0][rest_indices[0]-1]\n",
    "    x2 = structure.xyz[0][rest_indices[1]-1]\n",
    "    x3 = structure.xyz[0][rest_indices[2]-1]\n",
    "    G1 = dG_harmonic_rest_triple(x1,x2,x3)\n",
    "    \n",
    "# Compute dG4\n",
    "    time_in_ps, states, energies = xvg_tools.get_dhdl(f'{prefix}/{dataset}_RL/RUN{run}/dhdl.xvg')\n",
    "    # should we get just last few nanoseconds for estimating free energy?\n",
    "    time_in_ps = time_in_ps[::100] # stride to match xtc save frequency\n",
    "    states = states[::100]\n",
    "    energies = energies[::100]\n",
    "\n",
    "    traj = md.load(f'{prefix}/{dataset}_RL/RUN{run}/traj.xtc',\n",
    "      top=f'{prefix}/{dataset}_RL/RUN{run}/npt.gro') # <-- get distances from here?\n",
    "    \n",
    "    dG4, sigma_dG4 = dG_restraint_MBAR(states, energies, distances, kvalue=800, # kJ/mol/nm^2\n",
    "        r0=r0, temperature=298.15, verbose=False) # <-- will fix u_kn for multi-restraints\n",
    "    \n",
    "    FEB = dG1 + dG2 + dG3 + dG4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dG_harmonic_rest_triple(x1,x2,x3, k=800.0, L=1.184048, verbose=False):\n",
    "\n",
    "    \"\"\"Returns the free energy of turning on a triple harmonic restraint in units RT, \n",
    "    for a rigid nonlinear molecule restrained at anchors x1, x2, and x3\n",
    "    INPUTS\n",
    "    x1, x2, x3 - the coordinates of the three restraint positions as 3-element np.array(), each in units nm\n",
    "    PARAMETERS\n",
    "    k      - the force constant, in kJ/mol/nm^2  (Default: 800.0 kJ/mol/nm^2)\n",
    "    L      - the length of the cubic box (Default: 1.184048 nm ) \n",
    "                V0 = 1660.0                   # in Angstrom^3 is the standard volume\n",
    "                L0 = ((1660.0)**(1/3)) * 0.1  # converted to nm\n",
    "                L0 = 1.1840481475428983 nm\n",
    "    \"\"\"\n",
    "\n",
    "    RT      = 2.479           # in kJ/mol at 298 K\n",
    "\n",
    "\n",
    "    # Calculate distance between particles 1 and 2\n",
    "    d = np.sqrt( np.dot(x2-x1,x2-x1) )\n",
    "    #d = md_compute_distances(structure, [indices[0],indices[1]])[0]    \n",
    "    # Calculate the altitude (height), c, of triangle where p1-p2 is the base\n",
    "    ### 1. First calculate the area of the triangle as A = (1/2)||v \\cross w||\n",
    "    v, w = x2-x1, x3-x1\n",
    "    area = 0.5*np.linalg.norm( np.cross(v,w) )\n",
    "    ### 2. Then since A = 1/2 * base * height, the height is c = 2*area/base\n",
    "    c = 2.0 * area / np.linalg.norm(v)\n",
    "        \n",
    "    # Calculate e, the projection of x3-x1 = w in the x2-x1 = v direction\n",
    "    unit_vec_along_x12 = v / d\n",
    "    e = np.abs(np.dot(w, unit_vec_along_x12))\n",
    "        \n",
    "    if verbose:\n",
    "        print('Distance betweeen x1 and x2, \\td =', d, 'nm')\n",
    "        print('Height of x3 from triangular base x1-x2, \\tc =', c, 'nm')\n",
    "        print('Projection of x3-x1 in the x2-x1 direction, \\te =', e, 'nm')\n",
    "\n",
    "    kc_coeff = 1.0 + (e/d)**2.0\n",
    "    if verbose:\n",
    "        print('kc_coeff', kc_coeff)\n",
    "    kp1_coeff = 1.0 + (c**2 + e**2)/(d**2)\n",
    "    if verbose:\n",
    "        print('kp1_coeff', kp1_coeff)\n",
    "\n",
    "    '''\n",
    "        theory_dG_in_kT = -1.0*( 3.0/2.0*np.log(2.0*np.pi*ee.RT/(3.0*ee.k_values[1:]))        \\ # translational\n",
    "                                + 1.0/2.0*np.log(2.0*np.pi*ee.RT/(2.0*ee.k_values[1:]))       \\ # rot about d\n",
    "                                + 1.0/2.0*np.log(2.0*np.pi*ee.RT/(kc_coeff*ee.k_values[1:]))  \\ # rot about c\n",
    "                                + 1.0/2.0*np.log(2.0*np.pi*ee.RT/(kp1_coeff*ee.k_values[1:])) \\ # rot out of page\n",
    "                                - np.log( ee.L**3 * 8.0 * (np.pi**2) * (ee.d)**2 * ee.c  ) )\n",
    "    '''\n",
    "\n",
    "    theory_dG_in_kT = -1.0*( 3.0/2.0*np.log(2.0*np.pi*RT/(3.0*k))            \\\n",
    "                                + 1.0/2.0*np.log(2.0*np.pi*RT/k)             \\\n",
    "                                + 1.0/2.0*np.log(2.0*np.pi*RT/(kc_coeff*k))  \\\n",
    "                                + 1.0/2.0*np.log(2.0*np.pi*RT/(kp1_coeff*k)) \\\n",
    "                                - np.log( L**3 * 8.0 * (np.pi**2) * d**2 * c  ) )\n",
    "    return theory_dG_in_kT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dG_restraint_MBAR(states, energies, distances,\n",
    "                         kvalue=800.0, r0=0.4, temperature=300., verbose=False):\n",
    "    \"\"\"Use MBAR to estimate the free energy vs. lambda.\n",
    "    N is the number of samples\n",
    "    K is the number of thermodynamic states\n",
    "\n",
    "    INPUTS\n",
    "    states    - state indices in a numpy array of shape (N,)\n",
    "    energies  - a numpy array of shape (N, K) with the dhdl info\n",
    "    distances - restraint distances numpy array of shape (N,)\n",
    "\n",
    "    PARAMETERS\n",
    "    kvalue      - the harmonic force constant in kJ/nm^2 (Default: 400.0)\n",
    "    r0          - the restraint distance umbrella center, in nm.\n",
    "    temperature - in K (Default: 300.0)\n",
    "    verbose     - print verbose output\n",
    "\n",
    "    OUTPUT\n",
    "    \"\"\"\n",
    "\n",
    "    ###########################\n",
    "    # Main\n",
    "\n",
    "    # Physical constants (in kJ)\n",
    "    kB = 1.381e-23 * 6.022e23 / 1000.0 # Boltzmann constant in kJ/mol/K\n",
    "\n",
    "    # In addition to the given K thermo ensembles with indices 0,..K-1,\n",
    "    # there is one more -- the *unbiased* ensemble with no harmonic restraint.\n",
    "    #  -- let's make it state index K\n",
    "    K = energies.shape[1] + 1\n",
    "    unbiased_state_index = K - 1\n",
    "\n",
    "\n",
    "    # maximum number of snapshots/simulation:\n",
    "    N_max = energies.shape[0]\n",
    "    ### TO DO in the future collect *all* run and clone energies and flatten\n",
    "\n",
    "    T_k = np.ones(K,float)*temperature # inital temperatures are all equal\n",
    "    beta = 1.0 / (kB * temperature) # inverse temperature of simulations (in 1/(kJ/mol))\n",
    "    if verbose:\n",
    "        print('beta',  beta)\n",
    "\n",
    "    # Allocate storage for simulation data\n",
    "    N_k = np.zeros([K], np.int32) # N_k[k] is the number of snapshots from umbrella simulation k\n",
    "    # rvalues[k] is the spring center location (in nm) for umbrella simulation k\n",
    "    x_kn = np.zeros([K,N_max], np.float64) # x_kn[k,n] is the Val122_CA-TRP_CA distance (in nm) for snapshot n from umbrella simulation k\n",
    "    u_kn = np.zeros([K,N_max], np.float64) # u_kn[k,n] is the reduced potential energy without umbrella restraints of snapshot n of umbrella simulation k\n",
    "    g_k = np.zeros([K],np.float32);\n",
    "\n",
    "\n",
    "    ### To do MBAR, we need to convert to data to u_kn format\n",
    "    if verbose:\n",
    "        print('np.argsort(states)', np.argsort(states))\n",
    "\n",
    "    Ind = np.argsort(states)\n",
    "    energies_sorted = energies[Ind,:]\n",
    "    states_sorted = states[Ind]\n",
    "    distances_sorted = distances[Ind]\n",
    "    for k in range(K-1):\n",
    "\n",
    "        # Count how many snapshots belong to each k\n",
    "        N_k[k] = np.where(states_sorted == k, 1, 0).sum()\n",
    "\n",
    "        # fill the energies\n",
    "        u_kn[k, :] = energies_sorted[:, k]\n",
    "\n",
    "    # for the last (unbiased) ensemble (with no samples), subtract the harmonic potential from the\n",
    "    # state index 0 (totally coupled) eneries\n",
    "    u_kn[K-1, :] = u_kn[0, :] - beta * (kvalue/2.0) * (distances_sorted - r0)**2\n",
    "    if verbose:\n",
    "        print('u_kn', u_kn)\n",
    "        print('N_k', N_k)\n",
    "\n",
    "    # Initialize MBAR.\n",
    "    if verbose:\n",
    "        print('Running MBAR...')\n",
    "    mbar = pymbar.MBAR(u_kn, N_k, verbose=verbose)  #, maximum_iterations=100000, initialize='BAR')  \n",
    "\n",
    "    # MBAR(u_kn, N_k, maximum_iterations=10000, relative_tolerance=1e-07, verbose=False, initial_f_k=None, solver_protocol=None, initialize='zeros', x_kindices=None, **kwargs))\n",
    "\n",
    "    # Set zero of u_kn -- this is arbitrary.\n",
    "    u_kn -= u_kn.min()\n",
    "\n",
    "    results = mbar.getFreeEnergyDifferences()\n",
    "    Deltaf_ij, dDeltaf_ij = results[0], results[1]\n",
    "    if verbose:\n",
    "        print('Deltaf_ij, dDeltaf_ij', Deltaf_ij, dDeltaf_ij)\n",
    "\n",
    "    df, sigma_df = np.zeros(K), np.zeros(K)\n",
    "    for i in range(K-1):\n",
    "        #  print('Deltaf_%d,%d = '%(i,i+1), Deltaf_ij[i,i+1], '+/-', dDeltaf_ij[i,i+1])\n",
    "        df[i+1] = df[i] + Deltaf_ij[i,i+1]\n",
    "        sigma_df[i+1] = dDeltaf_ij[0,i+1]\n",
    "\n",
    "    dG_rest       = df[0] - df[-1]      # THIS should be the same as +f[-1] of the MBAR object!\n",
    "    sigma_dG_rest = sigma_df[-1]\n",
    "\n",
    "    if verbose:\n",
    "        print('Delta f (norest, lam=1 -> rest, lam=1) =', df[0] - df[-1])\n",
    "        print('dDelta f (norest, lam=1 -> rest, lam=1) =', sigma_df[-1])\n",
    "\n",
    "    return dG_rest, sigma_dG_rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710]\n"
     ]
    }
   ],
   "source": [
    "import mdtraj as md\n",
    "traj = md.load('REF_RL/RUN0/traj_comp.xtc',top='REF_RL/RUN0/xtc.gro')\n",
    "print([a.index for a in traj.topology.atoms if a.residue.name == 'LIG'])\n",
    "# NOTE that if you want LIG atoms you have to specify a.index < ~200\n",
    "# bc some other residues got re-named :\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
