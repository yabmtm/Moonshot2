{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of the absolute free energy of binding\n",
    "\n",
    "The free energy of binding for each simulation system is estimated from a series of legs along a thermodynamic cycle. The ∆G of binding should be:\n",
    "\n",
    "<center>\n",
    "∆G_1 + ∆G_2 + ∆G_3 + ∆G_4\n",
    "</center>\n",
    "\n",
    "where\n",
    "* ∆G_1 is the free energy of restraining ligand in solution (analytical)\n",
    "* ∆G_2 is the free energy of decoupling the ligand in solution  (EE)\n",
    "* ∆G_3 is the free energy of re-coupling the ligand bound to the receptor in the presence of restraints (EE)\n",
    "* ∆G_4 is the free energy of removing the three position restraints on the  ligand bound to the receptor (MBAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### %ls\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mdtraj as md\n",
    "import subprocess, collections\n",
    "import glob, tqdm, os\n",
    "import xvg_tools\n",
    "import harmonic_analytical\n",
    "import pymbar\n",
    "rc('font', weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace structure in dG1 with first frame of centered trajectory fil|e\n",
    "# Replace distances in dG4 AND change MBAR function to compute potential for THREE restraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n",
      "Looking for scraped_RL_feb_path ../data/combined/results/x11294/scraped_data/x11294_RL_RUN0_feb.npy True\n",
      "Looking for scraped_L_feb_path ../data/combined/results/x11294/scraped_data/x11294_L_RUN0_feb.npy True\n",
      "Reading ../data/combined/x11294_RL/RUN0/LIG_res.itp ...\n",
      "...Done.\n",
      "Restraint indices: [7, 24, 15]\n",
      "Reading ../data/combined/x11294_RL/RUN0/npt.gro ...\n",
      "boxsize    7.32884   7.32884   7.32884\n",
      "\n",
      "boxlength 7.32884\n",
      "Found grolines ['  305LIG      C    7   1.243   0.120   2.391\\n', '  305LIG      C   24   0.552   0.183   1.686\\n', '  305LIG      C   15   0.697   7.134   2.176\\n']\n",
      "Positions before PBC correction:\n",
      "[array([1.243, 0.12 , 2.391]), array([0.552, 0.183, 1.686]), array([0.697, 7.134, 2.176])]\n",
      "Positions after PBC correction:\n",
      "[array([1.243, 0.12 , 2.391]), array([0.552, 0.183, 1.686]), array([ 0.697  , -0.19484,  2.176  ])]\n",
      "Distance betweeen x1 and x2, \td = 0.9891789524651241 nm\n",
      "Height of x3 from triangular base x1-x2, \tc = 0.4226791849004529 nm\n",
      "Projection of x3-x1 in the x2-x1 direction, \te = 0.5145945318907774 nm\n",
      "kc_coeff 1.2706329055437167\n",
      "kp1_coeff 1.4532208033930347\n",
      "dG_rest_in_kT (triple): 3.6856386398007266\n",
      "rest_indices [7, 24, 15]\n",
      "Could not find ../data/combined/x11294_RL/RUN0/traj_comp.gro , now making one...\n",
      ">> echo \"26\\n\" | gmx editconf -f ../data/combined/x11294_RL/RUN0/npt.gro -n ../data/combined/x11294_RL/RUN0/index.ndx -o ../data/combined/x11294_RL/RUN0/traj_comp.gro\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/combined/x11294_RL/RUN0/traj_comp.gro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b864bded346a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Read in the traj_comp.xtc trajectory data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraj_comp_gro_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'traj.xyz.shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mdtraj/core/trajectory.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename_or_filenames, discard_overlapping_frames, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mtopkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"atom_indices\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mtopkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"top\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"top\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtopkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;31m# grab the extension of the filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mdtraj/core/trajectory.py\u001b[0m in \u001b[0;36m_parse_topology\u001b[0;34m(top, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mtopology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mol2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'.gro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mtopology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_gro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'.arc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mtopology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_arc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mdtraj/formats/gro.py\u001b[0m in \u001b[0;36mload_gro\u001b[0;34m(filename, stride, atom_indices, frame)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmdtraj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_parse_topology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mGroTrajectoryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mtopology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mdtraj/formats/gro.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, force_overwrite)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_atoms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/combined/x11294_RL/RUN0/traj_comp.gro'"
     ]
    }
   ],
   "source": [
    "dataset = 'x11294'\n",
    "prefix = '../data/combined'\n",
    "\n",
    "\n",
    "verbose = True\n",
    "debug = False\n",
    "\n",
    "\n",
    "for run in range(len(glob.glob(f'{prefix}/{dataset}_RL/RUN*'))):\n",
    "    if verbose:\n",
    "        print('run', run)\n",
    "    scraped_RL_feb_path = f'{prefix}/results/{dataset}/scraped_data/{dataset}_RL_RUN{run}_feb.npy'\n",
    "    scraped_L_feb_path = f'{prefix}/results/{dataset}/scraped_data/{dataset}_L_RUN{run}_feb.npy'\n",
    "    if verbose:\n",
    "        print('Looking for scraped_RL_feb_path', scraped_RL_feb_path, os.path.exists(scraped_RL_feb_path))\n",
    "        print('Looking for scraped_L_feb_path', scraped_L_feb_path, os.path.exists(scraped_L_feb_path))\n",
    "          \n",
    "    if not os.path.exists(scraped_RL_feb_path) or not os.path.exists(scraped_L_feb_path):\n",
    "        continue # skip if we don't have scraped free energies for dG2 and dG3\n",
    "    \n",
    "    # Note: all dG are in units kT \n",
    "    \n",
    "    ####################### \n",
    "    # Compute dG1 -  the free energy of restraining the ligand in a solution\n",
    "    #                at standard concentration (analytical)\n",
    "    \n",
    "    grofile = f'{prefix}/{dataset}_RL/RUN{run}/npt.gro'\n",
    "    itpfile = f'{prefix}/{dataset}_RL/RUN{run}/LIG_res.itp'\n",
    "    \n",
    "    dG1, rest_function_used = harmonic_analytical.get_dG_harmonic_rest(grofile, itpfile)\n",
    "    \n",
    "    ####################### \n",
    "    # Compute dG2 -   free energy of decoupling the ligand in solution (EE)\n",
    "    \n",
    "    L_increments = np.load(f'{prefix}/results/{dataset}/scraped_data/{dataset}_L_RUN{run}_inc.npy')\n",
    "    L_fe = np.load(f'{prefix}/results/{dataset}/scraped_data/{dataset}_L_RUN{run}_feb.npy')[:,-1]\n",
    "    \n",
    "    increment_threshold = 0.1\n",
    "    \n",
    "    for x,i in enumerate(L_increments):\n",
    "        if i < increment_threshold:\n",
    "            break\n",
    "    #print(np.shape(L_fe), x, np.average(L_fe[x:]), L_fe[-1]) # < --- decide which to use\n",
    "    dG2, dG2_sigma = np.average(L_fe[x:]), np.std(L_fe[x:])\n",
    "    \n",
    "    ####################### \n",
    "    # Compute dG3 -   free energy of *coupling* the ligand bound to the receptor\n",
    "    #                 in the presence of restraints (EE)\n",
    "    \n",
    "    RL_increments = np.load(f'{prefix}/results/{dataset}/scraped_data/{dataset}_RL_RUN{run}_inc.npy')\n",
    "    RL_fe = np.load(f'{prefix}/results/{dataset}/scraped_data/{dataset}_RL_RUN{run}_feb.npy')[:,-1]\n",
    "                    \n",
    "    for x,i in enumerate(RL_increments):\n",
    "        if i < increment_threshold:\n",
    "            last_frames = x*10 # un-stride for later\n",
    "            break\n",
    "    #print(np.shape(RL_fe), x, np.average(RL_fe[x:]), RL_fe[-1])\n",
    "    dG3, dG3_sigma = -np.average(RL_fe[x:]), np.std(RL_fe[x:])\n",
    "    \n",
    "    \n",
    "    ####################### \n",
    "    # Compute dG4 -   is the free energy of removing the three position \n",
    "    #                 restraints on the ligand bound to the receptor (MBAR)\n",
    "    \n",
    "    ### Get the restraint indices from the itpfile\n",
    "    fin = open(itpfile, 'r')\n",
    "    lines = fin.readlines()\n",
    "    fin.close()\n",
    "    \n",
    "    rest_lines = [line for line in lines if (line[0] != ';' and line[0] != '[')]\n",
    "    rest_indices = []\n",
    "    for line in rest_lines:\n",
    "        fields = line.strip().split()\n",
    "        rest_indices.append( int(fields[0]) )\n",
    "    if verbose:\n",
    "        print('rest_indices', rest_indices)\n",
    "\n",
    "    \n",
    "    # Make sure we have the starting grofile and xtc traj file\n",
    "    xtc_path = f'{prefix}/{dataset}_RL/RUN{run}/traj_comp.xtc'\n",
    "    if not os.path.exists(xtc_path):\n",
    "        raise Exception(f\"Can't find {xtc_path}!\")\n",
    "    npt_gro_path = f'{prefix}/{dataset}_RL/RUN{run}/npt.gro'\n",
    "    if not os.path.exists(npt_gro_path):\n",
    "        raise Exception(f\"Can't find {npt_gro_path}!\")\n",
    "    \n",
    "    # check to see if we have built a gro file for the xtc\n",
    "    traj_comp_gro_path = f'{prefix}/{dataset}_RL/RUN{run}/traj_comp.gro'\n",
    "    if not os.path.exists(traj_comp_gro_path):\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Could not find {traj_comp_gro_path} , now making one...')\n",
    "        # check to see if the current index file has the Protein_LIG atom group\n",
    "        index_path = f'{prefix}/{dataset}_RL/RUN{run}/index.ndx'\n",
    "        index_traj_comp_path = f'{prefix}/{dataset}_RL/RUN{run}/traj_comp.ndx'\n",
    "        fin = open(index_path, 'r')\n",
    "        index_text = fin.read()\n",
    "        fin.close()\n",
    "        \n",
    "        # Find the indices of the [ Protein ] and [ LIG ] the atom groups\n",
    "        directives = [line for line in index_text.split('\\n') if (line.count('[ ') > 0)]\n",
    "        protein_index = directives.index('[ Protein ]')\n",
    "        lig_index = directives.index('[ LIG ]')\n",
    "        \n",
    "        has_Protein_LIG_group = (index_text.count('Protein_LIG') > 0)\n",
    "        if not has_Protein_LIG_group:\n",
    "            # make a new atom_group for Protein_LIG\n",
    "            cmd = f'echo \"{protein_index}|{lig_index}\\\\nq\\\\n\" | gmx make_ndx -n {index_path} -o {index_traj_comp_path}'\n",
    "            if verbose:\n",
    "                print('>>', cmd)    \n",
    "            os.system(cmd)\n",
    "            protein_lig_index = len(directives)  # the new one we just added\n",
    "            # save a traj_comp.gro with these atoms\n",
    "            cmd = f'echo \"{protein_lig_index}\\\\n\" | gmx editconf -f {npt_gro_path} -n {index_traj_comp_path} -o {traj_comp_gro_path}'\n",
    "            if verbose:\n",
    "                print('>>', cmd)    \n",
    "            os.system(cmd)\n",
    "        else:\n",
    "            protein_lig_index = directives.index('[ Protein_LIG ]')\n",
    "            # save a traj_comp.gro with these atoms\n",
    "            cmd = f'echo \"{protein_lig_index}\\\\n\" | gmx editconf -f {npt_gro_path} -n {index_path} -o {traj_comp_gro_path}'\n",
    "            if verbose:\n",
    "                print('>>', cmd)    \n",
    "            os.system(cmd)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # Read in the traj_comp.xtc trajectory data      \n",
    "    traj = md.load(xtc_path, top=traj_comp_gro_path)\n",
    "    if debug:\n",
    "        print('traj.xyz.shape', traj.xyz.shape)\n",
    "    \n",
    "    # slice out only the restrained atoms\n",
    "    Ind = np.array([i-1 for i in rest_indices])\n",
    "    traj_positions = traj.xyz[:,Ind,:]\n",
    "    traj_initial_position = traj_positions[0,:,:]\n",
    "    if debug:\n",
    "        print('traj_positions', traj_positions)\n",
    "    \n",
    "    # compile all possible periodic translations\n",
    "    pbc_vecs = traj.unitcell_vectors[0]  # there are pbc vecs for each *frame*, we just take from the first frame\n",
    "    if debug:\n",
    "        print('pbc_vecs', pbc_vecs)\n",
    "    all_pbc_translations = []\n",
    "    for i in [-1., 0., 1.]:\n",
    "        for j in [-1., 0., 1.]:\n",
    "            for k in [-1., 0., 1.]:\n",
    "                all_pbc_translations.append(i*pbc_vecs[0,:] + j*pbc_vecs[1,:] + k*pbc_vecs[2,:])\n",
    "    all_pbc_translations = np.array(all_pbc_translations)\n",
    "    if debug:\n",
    "        print('all_pbc_translations', all_pbc_translations)\n",
    "        print('all_pbc_translations.shape', all_pbc_translations.shape)\n",
    "    \n",
    "    # correct each frame\n",
    "    traj_positions_corrected = np.zeros(traj_positions.shape)\n",
    "    nframes, nparticles, ndims = traj_positions.shape[0], traj_positions.shape[1], traj_positions.shape[2]\n",
    "    for i in range(nframes):\n",
    "        for j in range(nparticles):\n",
    "            all_images = all_pbc_translations + traj_positions[i,j,:]\n",
    "            all_displacements_from_initial = all_images - traj_initial_position[j,:]\n",
    "            all_sqdistances = np.sum(all_displacements_from_initial*all_displacements_from_initial, axis=1)\n",
    "            # pick the closest image\n",
    "            traj_positions_corrected[i,j,:] = all_images[np.argmin(all_sqdistances),:]\n",
    "    \n",
    "    # compute the distances\n",
    "    traj_distances = np.zeros( (nframes, nparticles) )\n",
    "    for j in range(nparticles):\n",
    "        traj_displacements = traj_positions_corrected[:,j,:] - traj_positions_corrected[0,j,:]\n",
    "        traj_distances[:,j] = np.sqrt(np.sum(traj_displacements*traj_displacements, axis=1))\n",
    "    \n",
    "    # plot distandes over time\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for j in range(nparticles):\n",
    "        plt.plot(np.arange(nframes), traj_distances[:,j])\n",
    "    plt.xlabel('frame')\n",
    "    plt.ylabel('distance (nm)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for j in range(nparticles):\n",
    "        counts, bin_edges = np.histogram(traj_distances[:,j], bins=100, normed=True)\n",
    "        bin_centers = (bin_edges[0:-1] + bin_edges[1:])/2.0\n",
    "        plt.plot(bin_centers, counts, label=f'particle {j}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('distances from restrained positions (nm)')\n",
    "    plt.xlabel('distance (nm)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    total_sqdisp_from_first_frame = np.sum(traj_distances*traj_distances, axis=1)\n",
    "    if debug:\n",
    "        print('total_sqdisp_from_first_frame', total_sqdisp_from_first_frame)\n",
    "        print('np.max(total_sqdisp_from_first_frame)', np.max(total_sqdisp_from_first_frame))\n",
    "    \n",
    "    RT = 2.479 # RT in in kJ/mol at 298 K\n",
    "    kvalue = 800.0 # kJ/mol/nm^2\n",
    "    du_10 = -1.0*kvalue/2.0*total_sqdisp_from_first_frame/RT  # reduced du's of turning the restraint off.\n",
    "    if debug:\n",
    "        print('du_10', du_10)\n",
    "        print('np.min(du_10)', np.min(du_10))\n",
    "        print('np.mean( np.exp(-1.0*du_10)', np.mean( np.exp(-1.0*du_10)))\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    counts, bin_edges = np.histogram(du_10, bins=100)\n",
    "    bin_centers = (bin_edges[0:-1] + bin_edges[1:])/2.0\n",
    "    plt.plot(bin_centers, counts)\n",
    "    plt.xlabel('energy (kT)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    ### DONT USE EXP averageing for free energy estimation  -- to o much bias\n",
    "    dG4 = -1.0*np.log( np.mean( np.exp(-1.0*du_10) ) )\n",
    "    if debug:\n",
    "        print('dG4_EXP', dG4)\n",
    "\n",
    "    \n",
    "    du_10_subsampled = du_10[::20]  # subsample to 5%\n",
    "    dG4_BAR, dG4_BAR_sigma = pymbar.BAR(du_10_subsampled, np.array([0]), DeltaF=0.0, compute_uncertainty=True, uncertainty_method='BAR')\n",
    "    #               maximum_iterations=500, relative_tolerance=1e-12,\n",
    "    #               verbose=False, method='false-position', iterated_solution=True, return_dict=False)\n",
    "    if verbose:\n",
    "        print('dG4_BAR', dG4_BAR)\n",
    "\n",
    "    \n",
    "    dG_binding = dG1 + dG2 + dG3 + dG4_BAR\n",
    "    dG_binding_sigma = np.sqrt( dG2_sigma**2 + dG2_sigma**2 )\n",
    "    Kd = np.exp(dG_binding)\n",
    "    \n",
    "    log_Kd_sigma = dG_binding_sigma/np.log(10)\n",
    "    \n",
    "    print('------------------------------------------------------------')\n",
    "    print(f'{dataset}/RUN{run}')\n",
    "    print('------------------------------------------------------------')\n",
    "    print(f'dG1 = \\t{dG1}')\n",
    "    print(f'dG2 = \\t{dG2} +/- {dG2_sigma}')\n",
    "    print(f'dG3 = \\t{dG3} +/- {dG3_sigma}')\n",
    "    print(f'dG4 = \\t{dG4_BAR} +/- {dG4_BAR_sigma}')\n",
    "    print('-----------')\n",
    "    print(f'dG_binding (units RT)   = {dG_binding}')\n",
    "    print(f'dG_binding_uncertainty  = {dG_binding_sigma}')\n",
    "    print(f'Kd                      = %3.2e M'%Kd)\n",
    "    print(f'log_10 Kd               = %3.2f'%np.log10(Kd) )\n",
    "    print(f'log_10 Kd uncertainty   = %3.2f'%log_Kd_sigma )\n",
    "    print('------------------------------------------------------------')\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "traj = md.load('REF_RL/RUN0/traj_comp.xtc',top='REF_RL/RUN0/xtc.gro')\n",
    "print([a.index for a in traj.topology.atoms if a.residue.name == 'LIG'])\n",
    "# NOTE that if you want LIG atoms you have to specify a.index < ~200\n",
    "# bc some other residues got re-named :\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40 + 259 + 217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.random.random( (3,3) )\n",
    "print(f)\n",
    "\n",
    "print(f-f[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pymbar.BAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
